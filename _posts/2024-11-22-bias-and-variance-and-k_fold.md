---
#layout: post
title: 데이터 위클리 페이퍼 12 - 머신러닝 편향과 분산, K-폴드
date: 2024-11-22
description: # 검색어 및 글요약
categories: [Data_analysis, Weekly]        # 메인 카테고리, 하위 카테고리(생략가능)
tags:           # 반드시 소문자로 작성, 한글가능
- bias
- variance
- k_fold
#pin: true # 해당글을 홈에서 고정시킬지
#toc: false # 오른쪽 목차 설정
#comments: false # 댓글 설정

#image: # 미리보기 이미지 설정
#  path: /path/to/image # 경로
#  alt: image alternative text # 이미지 설명 (생략가능)

#mermaid: true # 다이어그램 생성 도구 (https://github.com/mermaid-js/mermaid)
#math : true # 수학도구
---

### 모델 학습 시 발생할 수 있는 편향과 분산에 대해 설명하고, 두 개념의 관계에 대해 설명해 주세요.
> 편향과 분산은 트레이드오프 관계에 있습니다. 즉, 하나를 줄이면 다른 하나가 증가하는 경향이 있습니다. 모델의 성능을 최적화하려면 이 둘 사이의 균형을 잘 맞춰야 합니다.   

- **고편향, 저분산:** 너무 단순한 모델로 인해 데이터의 복잡한 패턴을 제대로 학습하지 못해 편향이 높아지지만, 예측의 일관성은 유지됩니다.
- **저편향, 고분산:** 매우 복잡한 모델로 인해 학습 데이터에 과적합하여 분산이 높아지지만, 훈련 데이터에 대해서는 매우 정확한 예측을 할 수 있습니다.

### K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇인가요?
> K-폴드 교차 검증에서 K의 값을 선택할 때는 데이터셋의 크기, 계산 비용(리소스), 분산과 편향의 균형, 데이터의 특성 등을 종합적으로 고려해야 합니다. 일반적으로 5-폴드나 10-폴드 교차 검증이 많이 사용됩니다.    

- 데이터셋의 크기가 크면 k의 값을 상대적으로 작은 값으로 설정해도 충분합니다. (5 정도)
- k 값이 클 수록 각 폴드에 대해 모델을 더 많이 학습시켜야하므로 계산에 필요한 비용이 증가합니다. k 값이 작을 수록 계산 비용이 줄어들지만, 모델 평가의 변동성이 커질 수 있습니다.
- k 값이 클 수록 모델의 분산이 줄어들고, 더 정확한 평가가 가능하지만 편향(bias)는 증가할 수 있습니다. 반대로 k 값이 작을 수록 모델의 편향은 줄어들지만 모델 평가의 신뢰도를 떨어뜨릴 수 있습니다.
- 데이터가 균형 잡혀 있는 경우 어떤 k값을 사용해도 비교적 일관된 결과를 얻을 수 있습니다. 다만 데이터가 불균형한 경우 각 폴드에 모든 클래스가 충분히 포함되도록 신중하게 k값을 선택해야 합니다.